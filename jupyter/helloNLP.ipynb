{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.10 |Anaconda, Inc.| (default, Mar 23 2020, 17:58:33) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyltp\n",
    "import os\n",
    "\n",
    "LTP_DATA_DIR = \"D:/chris/model/ltp_data/\"\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdml = \"\"\"因临修试运行需求，昆明车辆段申请，CRH380A-2901动车组在昆明局集团公司昆明南站至曲靖北\n",
    "站间试运行一往返，试运行结束后入昆明动车所，具体安排如下（由动车所三场发车）:\n",
    "    1.2019年12月02日，在昆明南站至曲靖北站间试运行，经昆明南沪昆场、小团山线路所、嵩明、\n",
    "曲靖北运行。\n",
    "    2.列车编组：CRH380A-2901动车组，编组8辆，全长203m，总重406.9t。\n",
    "    3.试运行交路：0G55302—G55302—G55301—0G55301。\n",
    "    4.乘务担当：动车组司机由昆明局集团公司担当，随车机械师由昆明局集团公司担当。\n",
    "    5.车底交路及运行时刻：0G55302（动车所三场20:50开，昆明南沪昆场3道21:04到）－G55302\n",
    "（昆明南沪昆场3道21:28开，曲靖北3道22:25到）－G55301（曲靖北3道22:45开，昆明南沪昆场8\n",
    "道23:45到）－0G55301（昆明南沪昆场8道23:59开，昆明动车所00:13到）。遇抵触由调度调整。\n",
    "    6.试运行技术要求：按《昆明局集团公司车辆部关于重新公布动车组试运行方案的通知（车辆函\n",
    "〔2018〕74号）》文件要求执行。\n",
    "    7.未尽事宜按<昆明铁路局关于重新印发《昆明铁路局动车组试运行管理办法》的通知（昆铁辆〔\n",
    "2017〕102号）>、《昆明局集团公司车辆部关于重新公布动车组试运行方案的通知（车辆函〔201\n",
    "8〕74号）》及相关文件电报要求执行。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0——因临修试运行需求，昆明车辆段申请，CRH380A-2901动车组在昆明局集团公司昆明南站至曲靖北\n",
      "1——站间试运行一往返，试运行结束后入昆明动车所，具体安排如下（由动车所三场发车）:\n",
      "2——1.2019年12月02日，在昆明南站至曲靖北站间试运行，经昆明南沪昆场、小团山线路所、嵩明、\n",
      "3——曲靖北运行。\n",
      "4——\n",
      "5——2.列车编组：CRH380A-2901动车组，编组8辆，全长203m，总重406.9t。\n",
      "6——\n",
      "7——3.试运行交路：0G55302—G55302—G55301—0G55301。\n",
      "8——\n",
      "9——4.乘务担当：动车组司机由昆明局集团公司担当，随车机械师由昆明局集团公司担当。\n",
      "10——\n",
      "11——5.车底交路及运行时刻：0G55302（动车所三场20:50开，昆明南沪昆场3道21:04到）－G55302\n",
      "12——（昆明南沪昆场3道21:28开，曲靖北3道22:25到）－G55301（曲靖北3道22:45开，昆明南沪昆场8\n",
      "13——道23:45到）－0G55301（昆明南沪昆场8道23:59开，昆明动车所00:13到）。\n",
      "14——遇抵触由调度调整。\n",
      "15——\n",
      "16——6.试运行技术要求：按《昆明局集团公司车辆部关于重新公布动车组试运行方案的通知（车辆函\n",
      "17——〔2018〕74号）》文件要求执行。\n",
      "18——\n",
      "19——7.未尽事宜按<昆明铁路局关于重新印发《昆明铁路局动车组试运行管理办法》的通知（昆铁辆〔\n",
      "20——2017〕102号）>、《昆明局集团公司车辆部关于重新公布动车组试运行方案的通知（车辆函〔201\n",
      "21——8〕74号）》及相关文件电报要求执行。\n",
      "22——\n"
     ]
    }
   ],
   "source": [
    "## 分句\n",
    "from pyltp import SentenceSplitter\n",
    "sents = SentenceSplitter.split(kdml)\n",
    "print('\\n'.join(str(num)+'——'+s for num, s in zip(range(0, len(sents)), sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.车底交路及运行时刻：0G55302（动车所三场20:50开，昆明南沪昆场3道21:04到）－G55302'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.车底交路及运行时刻：0G55302（动车所三场20:50开，昆明南沪昆场3道21:04到）－G55302\\n（昆明南沪昆场3道21:28开，曲靖北3道22:25到）－G55301（曲靖北3道22:45开，昆明南沪昆场8\\n道23:45到）－0G55301（昆明南沪昆场8道23:59开，昆明动车所00:13到）。遇抵触由调度调整。'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdml = '''5.车底交路及运行时刻：0G55302（动车所三场20:50开，昆明南沪昆场3道21:04到）－G55302\n",
    "（昆明南沪昆场3道21:28开，曲靖北3道22:25到）－G55301（曲靖北3道22:45开，昆明南沪昆场8\n",
    "道23:45到）－0G55301（昆明南沪昆场8道23:59开，昆明动车所00:13到）。遇抵触由调度调整。'''\n",
    "kdml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.\t车底\t交路\t及\t运行\t时刻\t：\t0G55302\t（\t动车\t所\t三\t场\t20:50\t开\t，\t昆明\t南\t沪\t昆场\t3\t道\t21\t:\t04\t到\t）\t－\tG55302\t\n",
      "\t（\t昆明\t南\t沪\t昆场\t3\t道\t21\t:\t28\t开\t，\t曲靖北\t3\t道\t22\t:\t25\t到\t）\t－\tG55301\t（\t曲靖北\t3\t道\t22\t:\t45\t开\t，\t昆明\t南\t沪\t昆场\t8\n",
      "道\t23\t:\t45\t到\t）\t－\t0G55301\t（\t昆明\t南\t沪\t昆场\t8\t道\t23\t:\t59\t开\t，\t昆明\t动车\t所\t00\t:\t13\t到\t）\t。\t遇\t抵触\t由\t调度\t调整\t。\n"
     ]
    }
   ],
   "source": [
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(cws_model_path)  # 加载模型\n",
    "words = segmentor.segment(kdml)  # 分词\n",
    "print('\\t'.join(words))\n",
    "segmentor.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.(m)\t车底(n)\t交路(n)\t及(c)\t运行(v)\t时刻(n)\t：(wp)\t0G55302(m)\t（(wp)\t动车(n)\t所(u)\t三(m)\t场(q)\t20:50(m)\t开(v)\t，(wp)\t昆明(ns)\t南(nd)\t沪(j)\t昆场(n)\t3(m)\t道(q)\t21(m)\t:(wp)\t04(m)\t到(v)\t）(wp)\t－(wp)\tG55302(m)\t\n",
      "(n)\t（(wp)\t昆明(ns)\t南(nd)\t沪(j)\t昆场(n)\t3(m)\t道(q)\t21(m)\t:(wp)\t28(m)\t开(v)\t，(wp)\t曲靖北(ns)\t3(m)\t道(q)\t22(m)\t:(wp)\t25(m)\t到(v)\t）(wp)\t－(wp)\tG55301(ws)\t（(wp)\t曲靖北(ns)\t3(m)\t道(q)\t22(m)\t:(wp)\t45(m)\t开(v)\t，(wp)\t昆明(ns)\t南(nd)\t沪(j)\t昆场(n)\t8\n",
      "道(n)\t23(m)\t:(wp)\t45(m)\t到(v)\t）(wp)\t－(wp)\t0G55301(m)\t（(wp)\t昆明(ns)\t南(nd)\t沪(j)\t昆场(n)\t8(m)\t道(q)\t23(m)\t:(wp)\t59(m)\t开(v)\t，(wp)\t昆明(ns)\t动车(n)\t所(u)\t00(m)\t:(wp)\t13(m)\t到(v)\t）(wp)\t。(wp)\t遇(v)\t抵触(v)\t由(p)\t调度(v)\t调整(v)\t。(wp)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger\n",
    "\n",
    "# # 分词\n",
    "# cws_model_path = os.path.join(os.path.dirname(__file__), ‘data/cws.model‘)  # 分词模型路径，模型名称为`cws.model`\n",
    "# lexicon_path = os.path.join(os.path.dirname(__file__), ‘data/lexicon.txt‘)  # 参数lexicon是自定义词典的文件路径\n",
    "\n",
    "# segmentor = Segmentor()\n",
    "# segmentor.load_with_lexicon(cws_model_path, lexicon_path)\n",
    "\n",
    "# sent = ‘据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。‘\n",
    "# words = segmentor.segment(sent)  # 分词\n",
    "\n",
    "# 词性标注\n",
    "# pos_model_path = os.path.join(os.path.dirname(__file__), ‘data/pos.model‘)  # 词性标注模型路径，模型名称为`pos.model`\n",
    "\n",
    "postagger = Postagger()  # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "\n",
    "print('\\t'.join(w+'('+t+')' for w, t in zip(words, postags)))\n",
    "\n",
    "# 释放模型\n",
    "postagger.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-43-a7331375812c>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-a7331375812c>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    cws_model_path = os.path.join(os.path.dirname(__file__), ‘data/cws.model‘)  # 分词模型路径，模型名称为`cws.model`\u001b[0m\n\u001b[1;37m                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 命名实体识别（NER）指的是识别出一句话或一段话或一片文章中的命名实体，比如人名，地名，组织机构名。示例的Python代码ner.py如下：\n",
    "\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger\n",
    "\n",
    "# 分词\n",
    "cws_model_path = os.path.join(os.path.dirname(__file__), ‘data/cws.model‘)  # 分词模型路径，模型名称为`cws.model`\n",
    "lexicon_path = os.path.join(os.path.dirname(__file__), ‘data/lexicon.txt‘)  # 参数lexicon是自定义词典的文件路径\n",
    "\n",
    "segmentor = Segmentor()\n",
    "segmentor.load_with_lexicon(cws_model_path, lexicon_path)\n",
    "\n",
    "sent = ‘据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。‘\n",
    "words = segmentor.segment(sent)  # 分词\n",
    "\n",
    "# 词性标注\n",
    "pos_model_path = os.path.join(os.path.dirname(__file__), ‘data/pos.model‘)  # 词性标注模型路径，模型名称为`pos.model`\n",
    "\n",
    "postagger = Postagger()  # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "\n",
    "\n",
    "ner_model_path = os.path.join(os.path.dirname(__file__), ‘data/ner.model‘)   # 命名实体识别模型路径，模型名称为`pos.model`\n",
    "\n",
    "from pyltp import NamedEntityRecognizer\n",
    "recognizer = NamedEntityRecognizer() # 初始化实例\n",
    "recognizer.load(ner_model_path)  # 加载模型\n",
    "# netags = recognizer.recognize(words, postags)  # 命名实体识别\n",
    "\n",
    "\n",
    "# 提取识别结果中的人名，地名，组织机构名\n",
    "\n",
    "persons, places, orgs = set(), set(), set()\n",
    "\n",
    "\n",
    "netags = list(recognizer.recognize(words, postags))  # 命名实体识别\n",
    "print(netags)\n",
    "# print(netags)\n",
    "i = 0\n",
    "for tag, word in zip(netags, words):\n",
    "    j = i\n",
    "    # 人名\n",
    "    if ‘Nh‘ in tag:\n",
    "        if str(tag).startswith(‘S‘):\n",
    "            persons.add(word)\n",
    "        elif str(tag).startswith(‘B‘):\n",
    "            union_person = word\n",
    "            while netags[j] != ‘E-Nh‘:\n",
    "                j += 1\n",
    "                if j < len(words):\n",
    "                    union_person += words[j]\n",
    "            persons.add(union_person)\n",
    "    # 地名\n",
    "    if ‘Ns‘ in tag:\n",
    "        if str(tag).startswith(‘S‘):\n",
    "            places.add(word)\n",
    "        elif str(tag).startswith(‘B‘):\n",
    "            union_place = word\n",
    "            while netags[j] != ‘E-Ns‘:\n",
    "                j += 1\n",
    "                if j < len(words):\n",
    "                    union_place += words[j]\n",
    "            places.add(union_place)\n",
    "    # 机构名\n",
    "    if ‘Ni‘ in tag:\n",
    "        if str(tag).startswith(‘S‘):\n",
    "            orgs.add(word)\n",
    "        elif str(tag).startswith(‘B‘):\n",
    "            union_org = word\n",
    "            while netags[j] != ‘E-Ni‘:\n",
    "                j += 1\n",
    "                if j < len(words):\n",
    "                    union_org += words[j]\n",
    "            orgs.add(union_org)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(‘人名：‘, ‘，‘.join(persons))\n",
    "print(‘地名：‘, ‘，‘.join(places))\n",
    "print(‘组织机构：‘, ‘，‘.join(orgs))\n",
    "\n",
    "\n",
    "# 释放模型\n",
    "segmentor.release()\n",
    "postagger.release()\n",
    "recognizer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#依存语法 (Dependency Parsing, DP) 通过分析语言单位内成分之间的依存关系揭示其句法结构。 直观来讲，依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分之间的关系。示例的Python代码parser.py代码如下：\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger, Parser\n",
    "\n",
    "# 分词\n",
    "cws_model_path = os.path.join(os.path.dirname(__file__), ‘data/cws.model‘)  # 分词模型路径，模型名称为`cws.model`\n",
    "lexicon_path = os.path.join(os.path.dirname(__file__), ‘data/lexicon.txt‘)  # 参数lexicon是自定义词典的文件路径\n",
    "\n",
    "segmentor = Segmentor()\n",
    "segmentor.load_with_lexicon(cws_model_path, lexicon_path)\n",
    "\n",
    "sent = ‘据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。‘\n",
    "words = segmentor.segment(sent)  # 分词\n",
    "\n",
    "# 词性标注\n",
    "pos_model_path = os.path.join(os.path.dirname(__file__), ‘data/pos.model‘)  # 词性标注模型路径，模型名称为`pos.model`\n",
    "\n",
    "postagger = Postagger()  # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "\n",
    "\n",
    "# 依存句法分析\n",
    "par_model_path = os.path.join(os.path.dirname(__file__), ‘data/parser.model‘)  # 模型路径，模型名称为`parser.model`\n",
    "\n",
    "parser = Parser() # 初始化实例\n",
    "parser.load(par_model_path)  # 加载模型\n",
    "arcs = parser.parse(words, postags)  # 句法分析\n",
    "\n",
    "rely_id = [arc.head for arc in arcs]  # 提取依存父节点id\n",
    "relation = [arc.relation for arc in arcs]  # 提取依存关系\n",
    "heads = [‘Root‘ if id == 0 else words[id-1] for id in rely_id]  # 匹配依存父节点词语\n",
    "\n",
    "for i in range(len(words)):\n",
    "    print(relation[i] + ‘(‘ + words[i] + ‘, ‘ + heads[i] + ‘)‘)\n",
    "\n",
    "# 释放模型\n",
    "segmentor.release()\n",
    "postagger.release()\n",
    "parser.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语义角色标注是实现浅层语义分析的一种方式。在一个句子中，谓词是对主语的陈述或说明，指出“做什么”、“是什么”或“怎么样，代表了一个事件的核心，跟谓词搭配的名词称为论元。语义角色是指论元在动词所指事件中担任的角色。主要有：施事者（Agent）、受事者（Patient）、客体（Theme）、经验者（Experiencer）、受益者（Beneficiary）、工具（Instrument）、处所（Location）、目标（Goal）和来源（Source）等。示例的Python代码rolelabel.py如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger, Parser, SementicRoleLabeller\n",
    "\n",
    "# 分词\n",
    "cws_model_path = os.path.join(os.path.dirname(__file__), ‘data/cws.model‘)  # 分词模型路径，模型名称为`cws.model`\n",
    "lexicon_path = os.path.join(os.path.dirname(__file__), ‘data/lexicon.txt‘)  # 参数lexicon是自定义词典的文件路径\n",
    "\n",
    "segmentor = Segmentor()\n",
    "segmentor.load_with_lexicon(cws_model_path, lexicon_path)\n",
    "\n",
    "sent = ‘据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。‘\n",
    "words = segmentor.segment(sent)  # 分词\n",
    "\n",
    "# 词性标注\n",
    "pos_model_path = os.path.join(os.path.dirname(__file__), ‘data/pos.model‘)  # 词性标注模型路径，模型名称为`pos.model`\n",
    "\n",
    "postagger = Postagger()  # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "\n",
    "# 依存句法分析\n",
    "par_model_path = os.path.join(os.path.dirname(__file__), ‘data/parser.model‘)  # 模型路径，模型名称为`parser.model`\n",
    "\n",
    "parser = Parser() # 初始化实例\n",
    "parser.load(par_model_path)  # 加载模型\n",
    "arcs = parser.parse(words, postags)  # 句法分析\n",
    "\n",
    "# 语义角色标注\n",
    "srl_model_path = os.path.join(os.path.dirname(__file__), ‘data/pisrl.model‘)  # 语义角色标注模型目录路径\n",
    "labeller = SementicRoleLabeller() # 初始化实例\n",
    "labeller.load(srl_model_path)  # 加载模型\n",
    "roles = labeller.label(words, postags, arcs)  # 语义角色标注\n",
    "\n",
    "# 打印结果\n",
    "for role in roles:\n",
    "    print(words[role.index], end=‘ ‘)\n",
    "    print(role.index, \"\".join([\"%s:(%d,%d)\" % (arg.name, arg.range.start, arg.range.end) for arg in role.arguments]))\n",
    "\n",
    "# 释放模型\n",
    "segmentor.release()\n",
    "postagger.release()\n",
    "parser.release()\n",
    "labeller.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
